{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "251b23d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from src.data_utils import clean_text\n",
    "from src.next_token_dataset import CustomDataset, make_collate_fn\n",
    "from src.eval_lstm import compute_rouge\n",
    "from src.lstm_model import RNN\n",
    "from src.train_loop import train_epoch, evaluate\n",
    "\n",
    "from transformers import BertTokenizerFast\n",
    "from sklearn.model_selection import train_test_split\n",
    "from datasets import Dataset\n",
    "\n",
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "cc64e8bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read txt-file\n",
    "with open('data/raw_dataset.txt', 'r', encoding='utf-8') as f:\n",
    "    lines = f.readlines()\n",
    "\n",
    "# delete \\n\n",
    "texts = [line.strip() for line in lines if line.strip()]\n",
    "\n",
    "# clean data\n",
    "cleaned_dataset = [clean_text(text) for text in texts]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "6107f38d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\" user url awww that's a bummer you shoulda got david carr of third day to do it d\",\n",
       " \"is upset that he can't update his facebook by texting it and might cry as a result school today also blah \",\n",
       " ' user i dived many times for the ball managed to save 50 the rest go out of bounds',\n",
       " 'my whole body feels itchy and like its on fire',\n",
       " \" user no it's not behaving at all i'm mad why am i here because i can't see you all over there \"]"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_dataset[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "7ef42785",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save clearned txt\n",
    "\n",
    "output_path = 'data/cleaned_data.txt'\n",
    "\n",
    "os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
    "\n",
    "with open(output_path, 'w', encoding='utf-8') as f:\n",
    "    f.write('\\n'.join(cleaned_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "065979b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"bert-base-uncased\"\n",
    "\n",
    "tokenizer = BertTokenizerFast.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "2dfdb810",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pad_id - 0, sep_id - 102, unk_id - 100, vocab_size - 30522\n"
     ]
    }
   ],
   "source": [
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.add_special_tokens({'pad_token': '[PAD]'})\n",
    "\n",
    "pad_id = tokenizer.pad_token_id\n",
    "sep_id = tokenizer.sep_token_id\n",
    "unk_id = tokenizer.unk_token_id\n",
    "vocab_size = tokenizer.vocab_size\n",
    "\n",
    "print(f'pad_id - {pad_id}, sep_id - {sep_id}, unk_id - {unk_id}, vocab_size - {vocab_size}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "6d839504",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = Dataset.from_dict({\"text\": cleaned_dataset})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "16968fae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# токенизация батчами, без добавления [CLS]/[SEP] в каждую строку\n",
    "def tokenize_fn(batch):\n",
    "    return tokenizer(batch[\"text\"], add_special_tokens=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91c8ad1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map:   0%|          | 0/1600498 [00:00<?, ? examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1600498/1600498 [00:41<00:00, 38133.89 examples/s]\n",
      "Saving the dataset (1/1 shards): 100%|██████████| 1600498/1600498 [00:00<00:00, 2981927.65 examples/s]\n"
     ]
    }
   ],
   "source": [
    "ds_tok = ds.map(\n",
    "    lambda batch: tokenizer(batch[\"text\"], add_special_tokens=False),\n",
    "    batched=True,\n",
    "    batch_size=1000,\n",
    "    remove_columns=[\"text\"]\n",
    ")\n",
    "\n",
    "ds_tok.set_format(type=\"torch\")\n",
    "ds_tok.save_to_disk(\"data/tokenized_dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "855c2b4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 5310, 24471,  2140, 22091,  2860,  2860,  2008,  1005,  1055,  1037,\n",
      "        26352,  5017,  2017,  2323,  2050,  2288,  2585, 12385,  1997,  2353])\n",
      "user url awww that ' s a bummer you shoulda got david carr of third\n"
     ]
    }
   ],
   "source": [
    "print(ds_tok[0][\"input_ids\"][:20])\n",
    "print(tokenizer.decode(ds_tok[0][\"input_ids\"][:20]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da01f787",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total sequences: 1600498\n"
     ]
    }
   ],
   "source": [
    "all_ids = ds_tok['input_ids']\n",
    "\n",
    "try:\n",
    "    N = len(all_ids)\n",
    "except Exception:\n",
    "    all_ids = list(all_ids)\n",
    "    N = len(all_ids)\n",
    "\n",
    "print(\"Total sequences:\", N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fd72a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = np.arange(N)\n",
    "train_idx, test_idx = train_test_split(indices, test_size=0.10, random_state=42)\n",
    "train_idx, val_idx = train_test_split(train_idx, test_size=0.111111, random_state=42)\n",
    "\n",
    "print(\"Counts (indices):\", len(train_idx), len(val_idx), len(test_idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "3ee529dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = ds_tok.select(train_idx)\n",
    "val_ds   = ds_tok.select(val_idx)\n",
    "test_ds  = ds_tok.select(test_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "b0ca9adb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving the dataset (1/1 shards): 100%|██████████| 1280398/1280398 [00:08<00:00, 151945.32 examples/s]\n",
      "Saving the dataset (1/1 shards): 100%|██████████| 160050/160050 [00:01<00:00, 153994.99 examples/s]\n",
      "Saving the dataset (1/1 shards): 100%|██████████| 160050/160050 [00:01<00:00, 159443.63 examples/s]\n"
     ]
    }
   ],
   "source": [
    "os.makedirs(\"data\", exist_ok=True)\n",
    "\n",
    "# сохраняем\n",
    "train_ds.save_to_disk(\"data/train_ds\")\n",
    "val_ds.save_to_disk(\"data/val_ds\")\n",
    "test_ds.save_to_disk(\"data/test_ds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c0c61a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Переводим в torch формат\n",
    "\n",
    "train_ds.set_format(type=\"torch\", columns=[\"input_ids\"])\n",
    "val_ds.set_format(type=\"torch\", columns=[\"input_ids\"])\n",
    "test_ds.set_format(type=\"torch\", columns=[\"input_ids\"])\n",
    "\n",
    "train_dataset = CustomDataset(train_ds)\n",
    "val_dataset   = CustomDataset(val_ds)\n",
    "test_dataset   = CustomDataset(test_ds)\n",
    "\n",
    "pad_id = tokenizer.pad_token_id\n",
    "collate = make_collate_fn(pad_id=pad_id)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True, collate_fn=collate, num_workers=0, pin_memory=True)\n",
    "val_loader   = DataLoader(val_dataset,   batch_size=128, shuffle=False, collate_fn=collate, num_workers=0, pin_memory=True)\n",
    "test_loader  = DataLoader(test_dataset,  batch_size=128, shuffle=False, collate_fn=collate, num_workers=0, pin_memory=True)\n",
    "\n",
    "print(f'Loader is ready. Example batches: {len(train_ds)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "5f37950c",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = RNN(vacab_size=tokenizer.vocab_size, emb_dim=256, hidden=512, padding_idx=pad_id).to(device)\n",
    "criterion = torch.nn.CrossEntropyLoss(ignore_index=pad_id)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.002531905600554039)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "1be0b3dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "Обучение 1 прошло, оцениваем val_loss\n",
      "Оценили val_los на 1 эпохе, считаем rouge_scores\n",
      "Epoch 1/5  TrainLoss=4.773986  ValLoss=4.657450 \n",
      "cuda\n",
      "Обучение 2 прошло, оцениваем val_loss\n",
      "Оценили val_los на 2 эпохе, считаем rouge_scores\n",
      "Epoch 2/5  TrainLoss=4.755271  ValLoss=4.640446 \n",
      "cuda\n",
      "Обучение 3 прошло, оцениваем val_loss\n",
      "Оценили val_los на 3 эпохе, считаем rouge_scores\n",
      "Epoch 3/5  TrainLoss=4.742275  ValLoss=4.640017 \n",
      "cuda\n",
      "Обучение 4 прошло, оцениваем val_loss\n",
      "Оценили val_los на 4 эпохе, считаем rouge_scores\n",
      "Epoch 4/5  TrainLoss=4.732778  ValLoss=4.627054 \n",
      "cuda\n",
      "Обучение 5 прошло, оцениваем val_loss\n",
      "Оценили val_los на 5 эпохе, считаем rouge_scores\n",
      "Epoch 5/5  TrainLoss=4.726251  ValLoss=4.627170 \n"
     ]
    }
   ],
   "source": [
    "# Пример использования в цикле обучения\n",
    "num_epochs = 5\n",
    "for epoch in range(num_epochs):\n",
    "    print(device)\n",
    "    train_loss = train_epoch(model, train_loader, optimizer, criterion, device)\n",
    "    print(f'Обучение {epoch+1} прошло, оцениваем val_loss')\n",
    "    val_loss, val_acc = evaluate(model, val_loader, criterion, device)\n",
    "    print(f'Оценили val_los на {epoch+1} эпохе, считаем rouge_scores')\n",
    "    \n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}  TrainLoss={train_loss:.6f}  ValLoss={val_loss:.6f} \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "de6de79b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROUGE-1=0.0020  ROUGE-2=0.0002  ROUGE-L=0.0020\n"
     ]
    }
   ],
   "source": [
    "rouge_scores = compute_rouge(model, val_loader, tokenizer, device, pad_id)\n",
    "print(f\"ROUGE-1={rouge_scores['rouge1']:.4f}  ROUGE-2={rouge_scores['rouge2']:.4f}  ROUGE-L={rouge_scores['rougeL']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "4930adca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tatya\\AppData\\Local\\Temp\\ipykernel_24080\\403510866.py:12: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  loaded_model.load_state_dict(torch.load(model_path, map_location=device))\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for RNN:\n\tsize mismatch for emb.weight: copying a param with shape torch.Size([30522, 256]) from checkpoint, the shape in current model is torch.Size([30522, 128]).\n\tsize mismatch for rnn.weight_ih_l0: copying a param with shape torch.Size([2048, 256]) from checkpoint, the shape in current model is torch.Size([1024, 128]).\n\tsize mismatch for rnn.weight_hh_l0: copying a param with shape torch.Size([2048, 512]) from checkpoint, the shape in current model is torch.Size([1024, 256]).\n\tsize mismatch for rnn.bias_ih_l0: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for rnn.bias_hh_l0: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for norm.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for norm.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for out.weight: copying a param with shape torch.Size([30522, 512]) from checkpoint, the shape in current model is torch.Size([30522, 256]).",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[152]\u001b[39m\u001b[32m, line 12\u001b[39m\n\u001b[32m      9\u001b[39m loaded_model = RNN(vacab_size=tokenizer.vocab_size, emb_dim=\u001b[32m128\u001b[39m, hidden=\u001b[32m256\u001b[39m, padding_idx=pad_id).to(device)\n\u001b[32m     11\u001b[39m \u001b[38;5;66;03m# 2. загружаем веса\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m \u001b[43mloaded_model\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload_state_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     13\u001b[39m loaded_model.eval() \n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\tatya\\OneDrive\\Documents\\auto-completion-of-texts\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2584\u001b[39m, in \u001b[36mModule.load_state_dict\u001b[39m\u001b[34m(self, state_dict, strict, assign)\u001b[39m\n\u001b[32m   2576\u001b[39m         error_msgs.insert(\n\u001b[32m   2577\u001b[39m             \u001b[32m0\u001b[39m,\n\u001b[32m   2578\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mMissing key(s) in state_dict: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m. \u001b[39m\u001b[33m\"\u001b[39m.format(\n\u001b[32m   2579\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33m, \u001b[39m\u001b[33m\"\u001b[39m.join(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\u001b[33m'\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m missing_keys)\n\u001b[32m   2580\u001b[39m             ),\n\u001b[32m   2581\u001b[39m         )\n\u001b[32m   2583\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(error_msgs) > \u001b[32m0\u001b[39m:\n\u001b[32m-> \u001b[39m\u001b[32m2584\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m   2585\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mError(s) in loading state_dict for \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m\"\u001b[39m.format(\n\u001b[32m   2586\u001b[39m             \u001b[38;5;28mself\u001b[39m.\u001b[34m__class__\u001b[39m.\u001b[34m__name__\u001b[39m, \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[33m\"\u001b[39m.join(error_msgs)\n\u001b[32m   2587\u001b[39m         )\n\u001b[32m   2588\u001b[39m     )\n\u001b[32m   2589\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m _IncompatibleKeys(missing_keys, unexpected_keys)\n",
      "\u001b[31mRuntimeError\u001b[39m: Error(s) in loading state_dict for RNN:\n\tsize mismatch for emb.weight: copying a param with shape torch.Size([30522, 256]) from checkpoint, the shape in current model is torch.Size([30522, 128]).\n\tsize mismatch for rnn.weight_ih_l0: copying a param with shape torch.Size([2048, 256]) from checkpoint, the shape in current model is torch.Size([1024, 128]).\n\tsize mismatch for rnn.weight_hh_l0: copying a param with shape torch.Size([2048, 512]) from checkpoint, the shape in current model is torch.Size([1024, 256]).\n\tsize mismatch for rnn.bias_ih_l0: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for rnn.bias_hh_l0: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for norm.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for norm.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for out.weight: copying a param with shape torch.Size([30522, 512]) from checkpoint, the shape in current model is torch.Size([30522, 256])."
     ]
    }
   ],
   "source": [
    "# Путь для сохранения\n",
    "model_path = \"models/rnn_lm_3.pt\"\n",
    "\n",
    "# Сохраняем веса\n",
    "torch.save(model.state_dict(), model_path)\n",
    "\n",
    "# Для загрузки\n",
    "# 1. создаём объект модели с такой же архитектурой\n",
    "loaded_model = RNN(vacab_size=tokenizer.vocab_size, emb_dim=128, hidden=256, padding_idx=pad_id).to(device)\n",
    "\n",
    "# 2. загружаем веса\n",
    "loaded_model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "loaded_model.eval() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "a9e13a3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user facebook iphone app is"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "user facebook iphone app is on aim anymore luckily i have a blackberry bold but its not available yet either sometimes they never seem to be happening anymore its not available anywhere near me anymore\n"
     ]
    }
   ],
   "source": [
    "seed = train_ds[0][\"input_ids\"][:5]  \n",
    "\n",
    "# генерируем 30 токенов\n",
    "gen_tokens = loaded_model.generate(seed, max_len=30, temperature=1.0, pad_id=pad_id, device=device)\n",
    "\n",
    "# обратно в текст\n",
    "generated_text = tokenizer.decode(gen_tokens)\n",
    "print(tokenizer.decode(seed))\n",
    "print(generated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3aa292e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2ac2b11e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    hidden = trial.suggest_categorical('hidden', [128, 256])\n",
    "    emb = trial.suggest_categorical('emb', [64, 128])\n",
    "    lr = trial.suggest_loguniform('lr', 1e-4, 1e-2)\n",
    "    bs = trial.suggest_categorical('batch_size', [64, 128])\n",
    "\n",
    "    print(f'hidden - {hidden}, emb - {emb}, lr - {lr}, bs - {bs}')\n",
    "\n",
    "    model = RNN(vacab_size=tokenizer.vocab_size, emb_dim=emb, hidden=hidden, padding_idx=pad_id).to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    train_loader = DataLoader(train_ds, batch_size=bs, shuffle=True, collate_fn=collate)\n",
    "    val_loader = DataLoader(val_ds, batch_size=bs, collate_fn=collate)\n",
    "\n",
    "    # тренируем 2-3 эпохи для оценки\n",
    "    for epoch in range(3):\n",
    "        train_loss = train_epoch(model, train_loader, optimizer, criterion, device)\n",
    "\n",
    "    val_loss, _ = evaluate(model, val_loader, criterion, device)\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}  TrainLoss={train_loss:.6f}  ValLoss={val_loss:.6f} \")\n",
    "    \n",
    "    return val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a186602c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-07 18:49:21,133] A new study created in memory with name: no-name-973431bd-507a-43ae-b899-7b770b774ed4\n",
      "C:\\Users\\tatya\\AppData\\Local\\Temp\\ipykernel_24080\\1339637914.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  lr = trial.suggest_loguniform('lr', 1e-4, 1e-2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hidden - 256, emb - 64, lr - 0.0017035508745426862, bs - 128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-07 19:47:44,809] Trial 0 finished with value: 4.803939693408152 and parameters: {'hidden': 256, 'emb': 64, 'lr': 0.0017035508745426862, 'batch_size': 128}. Best is trial 0 with value: 4.803939693408152.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/3  TrainLoss=4.990696  ValLoss=4.803940 \n",
      "hidden - 256, emb - 64, lr - 0.0001526215550204981, bs - 64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tatya\\AppData\\Local\\Temp\\ipykernel_24080\\1339637914.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  lr = trial.suggest_loguniform('lr', 1e-4, 1e-2)\n",
      "[I 2025-11-07 20:16:21,679] Trial 1 finished with value: 5.0267214323454485 and parameters: {'hidden': 256, 'emb': 64, 'lr': 0.0001526215550204981, 'batch_size': 64}. Best is trial 0 with value: 4.803939693408152.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/3  TrainLoss=5.237299  ValLoss=5.026721 \n",
      "hidden - 128, emb - 64, lr - 0.0023673698576573182, bs - 64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tatya\\AppData\\Local\\Temp\\ipykernel_24080\\1339637914.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  lr = trial.suggest_loguniform('lr', 1e-4, 1e-2)\n",
      "[I 2025-11-07 20:36:08,485] Trial 2 finished with value: 4.94033248873874 and parameters: {'hidden': 128, 'emb': 64, 'lr': 0.0023673698576573182, 'batch_size': 64}. Best is trial 0 with value: 4.803939693408152.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/3  TrainLoss=5.146778  ValLoss=4.940332 \n",
      "hidden - 128, emb - 64, lr - 0.00024138561861527735, bs - 64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tatya\\AppData\\Local\\Temp\\ipykernel_24080\\1339637914.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  lr = trial.suggest_loguniform('lr', 1e-4, 1e-2)\n",
      "[I 2025-11-07 20:56:30,589] Trial 3 finished with value: 5.112500692681913 and parameters: {'hidden': 128, 'emb': 64, 'lr': 0.00024138561861527735, 'batch_size': 64}. Best is trial 0 with value: 4.803939693408152.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/3  TrainLoss=5.349908  ValLoss=5.112501 \n",
      "hidden - 256, emb - 64, lr - 0.00017227434526483054, bs - 128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tatya\\AppData\\Local\\Temp\\ipykernel_24080\\1339637914.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  lr = trial.suggest_loguniform('lr', 1e-4, 1e-2)\n",
      "[I 2025-11-07 21:22:43,093] Trial 4 finished with value: 5.037428610973325 and parameters: {'hidden': 256, 'emb': 64, 'lr': 0.00017227434526483054, 'batch_size': 128}. Best is trial 0 with value: 4.803939693408152.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/3  TrainLoss=5.245498  ValLoss=5.037429 \n",
      "hidden - 256, emb - 128, lr - 0.00047277333714852574, bs - 128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tatya\\AppData\\Local\\Temp\\ipykernel_24080\\1339637914.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  lr = trial.suggest_loguniform('lr', 1e-4, 1e-2)\n",
      "[I 2025-11-07 21:48:34,038] Trial 5 finished with value: 4.847082013499232 and parameters: {'hidden': 256, 'emb': 128, 'lr': 0.00047277333714852574, 'batch_size': 128}. Best is trial 0 with value: 4.803939693408152.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/3  TrainLoss=5.047105  ValLoss=4.847082 \n",
      "hidden - 128, emb - 128, lr - 0.001615389305921212, bs - 128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tatya\\AppData\\Local\\Temp\\ipykernel_24080\\1339637914.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  lr = trial.suggest_loguniform('lr', 1e-4, 1e-2)\n",
      "[I 2025-11-07 22:08:52,256] Trial 6 finished with value: 4.908108684507977 and parameters: {'hidden': 128, 'emb': 128, 'lr': 0.001615389305921212, 'batch_size': 128}. Best is trial 0 with value: 4.803939693408152.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/3  TrainLoss=5.130844  ValLoss=4.908109 \n",
      "hidden - 128, emb - 128, lr - 0.0005478540553670885, bs - 128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tatya\\AppData\\Local\\Temp\\ipykernel_24080\\1339637914.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  lr = trial.suggest_loguniform('lr', 1e-4, 1e-2)\n",
      "[I 2025-11-07 22:29:24,902] Trial 7 finished with value: 4.984924593742334 and parameters: {'hidden': 128, 'emb': 128, 'lr': 0.0005478540553670885, 'batch_size': 128}. Best is trial 0 with value: 4.803939693408152.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/3  TrainLoss=5.222438  ValLoss=4.984925 \n",
      "hidden - 128, emb - 64, lr - 0.004762147342500464, bs - 64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tatya\\AppData\\Local\\Temp\\ipykernel_24080\\1339637914.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  lr = trial.suggest_loguniform('lr', 1e-4, 1e-2)\n",
      "[I 2025-11-07 22:50:29,415] Trial 8 finished with value: 4.973390865043016 and parameters: {'hidden': 128, 'emb': 64, 'lr': 0.004762147342500464, 'batch_size': 64}. Best is trial 0 with value: 4.803939693408152.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/3  TrainLoss=5.175940  ValLoss=4.973391 \n",
      "hidden - 128, emb - 64, lr - 0.00018677366964054245, bs - 128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tatya\\AppData\\Local\\Temp\\ipykernel_24080\\1339637914.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  lr = trial.suggest_loguniform('lr', 1e-4, 1e-2)\n",
      "[I 2025-11-07 23:09:10,645] Trial 9 finished with value: 5.180746935363222 and parameters: {'hidden': 128, 'emb': 64, 'lr': 0.00018677366964054245, 'batch_size': 128}. Best is trial 0 with value: 4.803939693408152.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/3  TrainLoss=5.424884  ValLoss=5.180747 \n",
      "hidden - 256, emb - 128, lr - 0.0061540248639914315, bs - 128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tatya\\AppData\\Local\\Temp\\ipykernel_24080\\1339637914.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  lr = trial.suggest_loguniform('lr', 1e-4, 1e-2)\n",
      "[I 2025-11-07 23:33:04,641] Trial 10 finished with value: 4.8612921114637455 and parameters: {'hidden': 256, 'emb': 128, 'lr': 0.0061540248639914315, 'batch_size': 128}. Best is trial 0 with value: 4.803939693408152.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/3  TrainLoss=5.034828  ValLoss=4.861292 \n",
      "hidden - 256, emb - 128, lr - 0.0006468897805320586, bs - 128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tatya\\AppData\\Local\\Temp\\ipykernel_24080\\1339637914.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  lr = trial.suggest_loguniform('lr', 1e-4, 1e-2)\n",
      "[I 2025-11-07 23:57:04,339] Trial 11 finished with value: 4.821091150964733 and parameters: {'hidden': 256, 'emb': 128, 'lr': 0.0006468897805320586, 'batch_size': 128}. Best is trial 0 with value: 4.803939693408152.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/3  TrainLoss=5.018331  ValLoss=4.821091 \n",
      "hidden - 256, emb - 128, lr - 0.0009125617229595656, bs - 128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tatya\\AppData\\Local\\Temp\\ipykernel_24080\\1339637914.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  lr = trial.suggest_loguniform('lr', 1e-4, 1e-2)\n",
      "[I 2025-11-08 00:21:39,014] Trial 12 finished with value: 4.796645478445817 and parameters: {'hidden': 256, 'emb': 128, 'lr': 0.0009125617229595656, 'batch_size': 128}. Best is trial 12 with value: 4.796645478445817.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/3  TrainLoss=4.989104  ValLoss=4.796645 \n",
      "hidden - 256, emb - 128, lr - 0.001497242640437095, bs - 128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tatya\\AppData\\Local\\Temp\\ipykernel_24080\\1339637914.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  lr = trial.suggest_loguniform('lr', 1e-4, 1e-2)\n",
      "[I 2025-11-08 00:46:07,080] Trial 13 finished with value: 4.772119694380594 and parameters: {'hidden': 256, 'emb': 128, 'lr': 0.001497242640437095, 'batch_size': 128}. Best is trial 13 with value: 4.772119694380594.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/3  TrainLoss=4.960064  ValLoss=4.772120 \n",
      "hidden - 256, emb - 128, lr - 0.00272942869848902, bs - 128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tatya\\AppData\\Local\\Temp\\ipykernel_24080\\1339637914.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  lr = trial.suggest_loguniform('lr', 1e-4, 1e-2)\n",
      "[I 2025-11-08 01:10:56,974] Trial 14 finished with value: 4.77304741113222 and parameters: {'hidden': 256, 'emb': 128, 'lr': 0.00272942869848902, 'batch_size': 128}. Best is trial 13 with value: 4.772119694380594.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/3  TrainLoss=4.955103  ValLoss=4.773047 \n",
      "hidden - 256, emb - 128, lr - 0.003632813230835672, bs - 128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tatya\\AppData\\Local\\Temp\\ipykernel_24080\\1339637914.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  lr = trial.suggest_loguniform('lr', 1e-4, 1e-2)\n",
      "[I 2025-11-08 01:35:34,987] Trial 15 finished with value: 4.78775882877082 and parameters: {'hidden': 256, 'emb': 128, 'lr': 0.003632813230835672, 'batch_size': 128}. Best is trial 13 with value: 4.772119694380594.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/3  TrainLoss=4.967879  ValLoss=4.787759 \n",
      "hidden - 256, emb - 128, lr - 0.009046847475227915, bs - 128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tatya\\AppData\\Local\\Temp\\ipykernel_24080\\1339637914.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  lr = trial.suggest_loguniform('lr', 1e-4, 1e-2)\n",
      "[I 2025-11-08 02:00:15,913] Trial 16 finished with value: 4.96074625543443 and parameters: {'hidden': 256, 'emb': 128, 'lr': 0.009046847475227915, 'batch_size': 128}. Best is trial 13 with value: 4.772119694380594.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/3  TrainLoss=5.124602  ValLoss=4.960746 \n",
      "hidden - 256, emb - 128, lr - 0.002531905600554039, bs - 128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tatya\\AppData\\Local\\Temp\\ipykernel_24080\\1339637914.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  lr = trial.suggest_loguniform('lr', 1e-4, 1e-2)\n",
      "[I 2025-11-08 02:24:59,805] Trial 17 finished with value: 4.768335079518013 and parameters: {'hidden': 256, 'emb': 128, 'lr': 0.002531905600554039, 'batch_size': 128}. Best is trial 17 with value: 4.768335079518013.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/3  TrainLoss=4.952781  ValLoss=4.768335 \n",
      "hidden - 256, emb - 128, lr - 0.0012421043864707787, bs - 64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tatya\\AppData\\Local\\Temp\\ipykernel_24080\\1339637914.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  lr = trial.suggest_loguniform('lr', 1e-4, 1e-2)\n",
      "[I 2025-11-08 02:53:00,996] Trial 18 finished with value: 4.788338110526319 and parameters: {'hidden': 256, 'emb': 128, 'lr': 0.0012421043864707787, 'batch_size': 64}. Best is trial 17 with value: 4.768335079518013.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/3  TrainLoss=4.977030  ValLoss=4.788338 \n",
      "hidden - 256, emb - 128, lr - 0.0003026424639703648, bs - 128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tatya\\AppData\\Local\\Temp\\ipykernel_24080\\1339637914.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  lr = trial.suggest_loguniform('lr', 1e-4, 1e-2)\n",
      "[I 2025-11-08 03:17:44,308] Trial 19 finished with value: 4.8934129484978435 and parameters: {'hidden': 256, 'emb': 128, 'lr': 0.0003026424639703648, 'batch_size': 128}. Best is trial 17 with value: 4.768335079518013.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/3  TrainLoss=5.097664  ValLoss=4.893413 \n",
      "{'hidden': 256, 'emb': 128, 'lr': 0.002531905600554039, 'batch_size': 128}\n"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(direction='minimize')\n",
    "study.optimize(objective, n_trials=20)  # 20 экспериментов\n",
    "print(study.best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "36a0d8d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'hidden': 256, 'emb': 128, 'lr': 0.002531905600554039, 'batch_size': 128}\n"
     ]
    }
   ],
   "source": [
    "print(study.best_params)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
